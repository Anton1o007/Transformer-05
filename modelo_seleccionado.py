{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-06-25T13:48:51.380634Z\",\"iopub.execute_input\":\"2022-06-25T13:48:51.381241Z\",\"iopub.status.idle\":\"2022-06-25T13:48:51.904095Z\",\"shell.execute_reply.started\":\"2022-06-25T13:48:51.381138Z\",\"shell.execute_reply\":\"2022-06-25T13:48:51.903074Z\"}}\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\nfrom PIL import Image\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-06-25T13:48:57.645362Z\",\"iopub.execute_input\":\"2022-06-25T13:48:57.645729Z\",\"iopub.status.idle\":\"2022-06-25T13:48:59.543078Z\",\"shell.execute_reply.started\":\"2022-06-25T13:48:57.645699Z\",\"shell.execute_reply\":\"2022-06-25T13:48:59.542212Z\"}}\nimport glob\nimport torch\nimport torchvision\nfrom torchvision import datasets, transforms\nfrom torch import nn, optim\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader, sampler, random_split\nfrom torchvision import models\nfrom torch.utils.data import Dataset\nimport random\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-06-25T13:49:01.908549Z\",\"iopub.execute_input\":\"2022-06-25T13:49:01.909563Z\",\"iopub.status.idle\":\"2022-06-25T13:49:01.927348Z\",\"shell.execute_reply.started\":\"2022-06-25T13:49:01.909529Z\",\"shell.execute_reply\":\"2022-06-25T13:49:01.926481Z\"}}\nimport matplotlib.pyplot as plt\nimport os\nimport sys\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-06-25T13:49:03.939871Z\",\"iopub.execute_input\":\"2022-06-25T13:49:03.941009Z\",\"iopub.status.idle\":\"2022-06-25T13:49:03.94863Z\",\"shell.execute_reply.started\":\"2022-06-25T13:49:03.940939Z\",\"shell.execute_reply\":\"2022-06-25T13:49:03.947859Z\"}}\ntorchvision.__version__, torch.__version__ # ('0.11.2+cu102', '1.10.1+cu102')\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-06-25T13:49:05.464495Z\",\"iopub.execute_input\":\"2022-06-25T13:49:05.464953Z\",\"iopub.status.idle\":\"2022-06-25T13:49:05.479091Z\",\"shell.execute_reply.started\":\"2022-06-25T13:49:05.464914Z\",\"shell.execute_reply\":\"2022-06-25T13:49:05.478036Z\"}}\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed = 42\nseed_everything(seed)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-06-25T13:49:07.39866Z\",\"iopub.execute_input\":\"2022-06-25T13:49:07.399044Z\",\"iopub.status.idle\":\"2022-06-25T13:49:07.403749Z\",\"shell.execute_reply.started\":\"2022-06-25T13:49:07.399011Z\",\"shell.execute_reply\":\"2022-06-25T13:49:07.402818Z\"}}\ndevice = 'cuda'\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-06-25T13:49:08.667117Z\",\"iopub.execute_input\":\"2022-06-25T13:49:08.667582Z\",\"iopub.status.idle\":\"2022-06-25T13:49:08.672244Z\",\"shell.execute_reply.started\":\"2022-06-25T13:49:08.667545Z\",\"shell.execute_reply\":\"2022-06-25T13:49:08.671413Z\"}}\ntrain_dir = '../input/iais22-birds/birds/birds'\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-06-25T13:49:10.633887Z\",\"iopub.execute_input\":\"2022-06-25T13:49:10.634573Z\",\"iopub.status.idle\":\"2022-06-25T13:49:10.638573Z\",\"shell.execute_reply.started\":\"2022-06-25T13:49:10.634533Z\",\"shell.execute_reply\":\"2022-06-25T13:49:10.637788Z\"}}\ndef get_classes(data_dir):\n    all_data = datasets.ImageFolder(data_dir)\n    return all_data.classes\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-06-25T13:49:12.079588Z\",\"iopub.execute_input\":\"2022-06-25T13:49:12.079947Z\",\"iopub.status.idle\":\"2022-06-25T13:49:16.724618Z\",\"shell.execute_reply.started\":\"2022-06-25T13:49:12.079917Z\",\"shell.execute_reply\":\"2022-06-25T13:49:16.723694Z\"}}\ntrain_list = []\nclasses = get_classes(train_dir)\nfor c in classes:\n    train_list = train_list + (glob.glob(os.path.join(train_dir+\"/\"+c,'*.jpg')))\n\nprint(f\"Train Data: {len(train_list)}\")\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-06-25T13:49:19.056755Z\",\"iopub.execute_input\":\"2022-06-25T13:49:19.057456Z\",\"iopub.status.idle\":\"2022-06-25T13:49:19.085609Z\",\"shell.execute_reply.started\":\"2022-06-25T13:49:19.057419Z\",\"shell.execute_reply\":\"2022-06-25T13:49:19.084814Z\"}}\nlabels = [path.split('/')[-2] for path in train_list]\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-06-25T13:49:20.947691Z\",\"iopub.execute_input\":\"2022-06-25T13:49:20.94808Z\",\"iopub.status.idle\":\"2022-06-25T13:49:21.060714Z\",\"shell.execute_reply.started\":\"2022-06-25T13:49:20.948049Z\",\"shell.execute_reply\":\"2022-06-25T13:49:21.059866Z\"}}\ntrain_list, valid_list = train_test_split(train_list, \n                                          test_size=0.2,\n                                          stratify=labels,\n                                          random_state=seed)\n\nlabels2 = [path.split('/')[-2] for path in valid_list]\n\ntest_list, valid_list = train_test_split(valid_list, \n                                          test_size=0.2,\n                                          stratify=labels2,\n                                          random_state=seed)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-06-25T13:49:22.756718Z\",\"iopub.execute_input\":\"2022-06-25T13:49:22.757114Z\",\"iopub.status.idle\":\"2022-06-25T13:49:22.764838Z\",\"shell.execute_reply.started\":\"2022-06-25T13:49:22.757082Z\",\"shell.execute_reply\":\"2022-06-25T13:49:22.76408Z\"}}\nclass BirdsDataset(Dataset):\n    def __init__(self, file_list, transform=None):\n        self.file_list = file_list\n        self.transform = transform\n\n    def __len__(self):\n        self.filelength = len(self.file_list)\n        return self.filelength\n\n    def __getitem__(self, idx):\n        img_path = self.file_list[idx]\n        img = Image.open(img_path)\n        img_transformed = self.transform(img)\n\n        label = img_path.split(\"/\")[-2]\n        label = classes.index(label)\n\n        return img_transformed, label\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-06-25T13:49:24.965151Z\",\"iopub.execute_input\":\"2022-06-25T13:49:24.965795Z\",\"iopub.status.idle\":\"2022-06-25T13:49:24.978086Z\",\"shell.execute_reply.started\":\"2022-06-25T13:49:24.965759Z\",\"shell.execute_reply\":\"2022-06-25T13:49:24.977277Z\"}}\ndef get_data_loaders(data_dir, batch_size=64, train = False):\n    if train:\n        transform = transforms.Compose([\n            transforms.RandomHorizontalFlip(p=0.5),\n            transforms.RandomVerticalFlip(p=0.5),\n            transforms.RandomApply(torch.nn.ModuleList([transforms.ColorJitter(), \n                                                        transforms.GaussianBlur(3)]), p=0.1),\n            transforms.Resize(256),\n            transforms.CenterCrop(240),\n            transforms.ToTensor(),\n            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n            transforms.RandomErasing(p=0.14, value='random')\n        ])\n        train_data = BirdsDataset(train_list, transform=transform)\n        #print(f\"Found {len(train_data)} images for training with {len(train_data.classes)} classes\")\n        train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n        return train_loader, len(train_data)\n    \n    else:\n        transform = transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(240),\n            transforms.ToTensor(),\n            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n        ])\n        val_data = BirdsDataset(valid_list, transform=transform)\n        test_data = datasets.ImageFolder(\"../input/iais22-birds/birds/birds\", transform=transform)\n        #print(f\"Found {len(val_data)} images for validation with {len(val_data.classes)} classes\")\n        #print(f\"Found {len(test_data)} images for testing with {len(test_data.classes)} classes\")\n        val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n        test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True, num_workers=2)\n        return (val_loader, test_loader, len(val_data), len(test_data))\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-06-25T13:49:27.101808Z\",\"iopub.execute_input\":\"2022-06-25T13:49:27.102184Z\",\"iopub.status.idle\":\"2022-06-25T13:49:27.590655Z\",\"shell.execute_reply.started\":\"2022-06-25T13:49:27.102147Z\",\"shell.execute_reply\":\"2022-06-25T13:49:27.589702Z\"}}\n(train_loader, train_data_len) = get_data_loaders(\"../input/iais22-birds\", 256, train=True)\n(val_loader, test_loader, valid_data_len, test_data_len) = get_data_loaders(\"../input/iais22-birds\", 64, train=False)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-06-25T13:49:29.401904Z\",\"iopub.execute_input\":\"2022-06-25T13:49:29.40277Z\",\"iopub.status.idle\":\"2022-06-25T13:49:29.407721Z\",\"shell.execute_reply.started\":\"2022-06-25T13:49:29.402732Z\",\"shell.execute_reply\":\"2022-06-25T13:49:29.407018Z\"}}\ndataloaders = {\n    \"train\":train_loader,\n    \"val\": val_loader\n}\ndataset_sizes = {\n    \"train\":train_data_len,\n    \"val\": valid_data_len\n}\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-06-25T13:49:30.958477Z\",\"iopub.execute_input\":\"2022-06-25T13:49:30.958834Z\",\"iopub.status.idle\":\"2022-06-25T13:49:30.964132Z\",\"shell.execute_reply.started\":\"2022-06-25T13:49:30.958803Z\",\"shell.execute_reply\":\"2022-06-25T13:49:30.963231Z\"}}\nprint(len(train_loader))\nprint(len(val_loader))\nprint(len(test_loader))\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-06-25T13:49:33.188512Z\",\"iopub.execute_input\":\"2022-06-25T13:49:33.189124Z\",\"iopub.status.idle\":\"2022-06-25T13:49:33.193512Z\",\"shell.execute_reply.started\":\"2022-06-25T13:49:33.189087Z\",\"shell.execute_reply\":\"2022-06-25T13:49:33.192716Z\"}}\nprint(train_data_len, test_data_len, valid_data_len)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-06-25T13:49:34.968744Z\",\"iopub.execute_input\":\"2022-06-25T13:49:34.96914Z\",\"iopub.status.idle\":\"2022-06-25T13:49:45.300435Z\",\"shell.execute_reply.started\":\"2022-06-25T13:49:34.969107Z\",\"shell.execute_reply\":\"2022-06-25T13:49:45.299492Z\"}}\ndataiter = iter(train_loader)\nimages, labels = dataiter.next()\nimages = images.numpy() # convert images to numpy for display\n\n# plot the images in the batch, along with the corresponding labels\nfig = plt.figure(figsize=(25, 4))\nfor idx in np.arange(20):\n    ax = fig.add_subplot(2, int(20/2), idx+1, xticks=[], yticks=[])\n    plt.imshow(np.transpose(images[idx], (1, 2, 0)))\n    ax.set_title(classes[labels[idx]])\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-06-25T13:49:49.696839Z\",\"iopub.execute_input\":\"2022-06-25T13:49:49.697527Z\",\"iopub.status.idle\":\"2022-06-25T13:49:49.70549Z\",\"shell.execute_reply.started\":\"2022-06-25T13:49:49.697484Z\",\"shell.execute_reply\":\"2022-06-25T13:49:49.704317Z\"}}\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-06-25T13:49:51.757141Z\",\"iopub.execute_input\":\"2022-06-25T13:49:51.757811Z\",\"iopub.status.idle\":\"2022-06-25T13:49:53.769306Z\",\"shell.execute_reply.started\":\"2022-06-25T13:49:51.757768Z\",\"shell.execute_reply\":\"2022-06-25T13:49:53.768306Z\"}}\n## EFFICIENTNET B0\ntorch.backends.cudnn.benchmark = True\nmodel = models.efficientnet_b1(pretrained=True)\nfor param in model.parameters():\n    param.requires_grad = False\nn_inputs = model.classifier[1].in_features\nmodel.classifier = nn.Sequential(\n    nn.Linear(n_inputs,2048),\n    nn.SiLU(),\n    nn.Dropout(0.2),\n    nn.Linear(2048, len(classes))\n)\n\nmodel = model.to(device)\nprint(model.classifier)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-06-25T13:50:01.781715Z\",\"iopub.execute_input\":\"2022-06-25T13:50:01.782106Z\",\"iopub.status.idle\":\"2022-06-25T13:50:01.787546Z\",\"shell.execute_reply.started\":\"2022-06-25T13:50:01.782074Z\",\"shell.execute_reply\":\"2022-06-25T13:50:01.786711Z\"}}\ncriterion = nn.CrossEntropyLoss(label_smoothing=0.11)\ncriterion = criterion.to(device)\noptimizer = optim.AdamW(model.classifier.parameters(), lr=0.001)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-06-25T13:50:05.041648Z\",\"iopub.execute_input\":\"2022-06-25T13:50:05.042025Z\",\"iopub.status.idle\":\"2022-06-25T13:50:05.046209Z\",\"shell.execute_reply.started\":\"2022-06-25T13:50:05.041973Z\",\"shell.execute_reply\":\"2022-06-25T13:50:05.045261Z\"}}\ntraining_history = {'accuracy':[],'loss':[]}\nvalidation_history = {'accuracy':[],'loss':[]}\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-06-25T13:50:06.72776Z\",\"iopub.execute_input\":\"2022-06-25T13:50:06.728666Z\",\"iopub.status.idle\":\"2022-06-25T13:50:06.733807Z\",\"shell.execute_reply.started\":\"2022-06-25T13:50:06.728616Z\",\"shell.execute_reply\":\"2022-06-25T13:50:06.732355Z\"}}\nfrom tqdm import tqdm\nimport time\nimport copy\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-06-25T13:50:11.41904Z\",\"iopub.execute_input\":\"2022-06-25T13:50:11.41952Z\",\"iopub.status.idle\":\"2022-06-25T13:50:11.424775Z\",\"shell.execute_reply.started\":\"2022-06-25T13:50:11.41948Z\",\"shell.execute_reply\":\"2022-06-25T13:50:11.423768Z\"}}\nexp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.5)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-06-25T13:50:13.799098Z\",\"iopub.execute_input\":\"2022-06-25T13:50:13.799631Z\",\"iopub.status.idle\":\"2022-06-25T13:50:13.813027Z\",\"shell.execute_reply.started\":\"2022-06-25T13:50:13.799594Z\",\"shell.execute_reply\":\"2022-06-25T13:50:13.812261Z\"}}\ndef train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n    since = time.time()\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for inputs, labels in tqdm(dataloaders[phase]):\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n            if phase == 'train':\n                scheduler.step()\n\n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n            \n            if phase == 'train':\n                training_history['accuracy'].append(epoch_acc)\n                training_history['loss'].append(epoch_loss)\n            elif phase == 'val':\n                validation_history['accuracy'].append(epoch_acc)\n                validation_history['loss'].append(epoch_loss)\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n\n            # deep copy the model\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed // 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-06-25T13:51:05.011759Z\",\"iopub.execute_input\":\"2022-06-25T13:51:05.012144Z\",\"iopub.status.idle\":\"2022-06-25T13:59:09.632484Z\",\"shell.execute_reply.started\":\"2022-06-25T13:51:05.012114Z\",\"shell.execute_reply\":\"2022-06-25T13:59:09.631515Z\"}}\nmodel_ft = train_model(model, criterion, optimizer, exp_lr_scheduler,\n                       num_epochs=2)\n\n# %% [code]\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-06-25T13:59:17.194887Z\",\"iopub.execute_input\":\"2022-06-25T13:59:17.195742Z\",\"iopub.status.idle\":\"2022-06-25T13:59:17.207942Z\",\"shell.execute_reply.started\":\"2022-06-25T13:59:17.1957Z\",\"shell.execute_reply\":\"2022-06-25T13:59:17.207141Z\"}}\ndef test(model):\n  test_loss = 0.0\n  class_correct = list(0. for i in range(len(classes)))\n  class_total = list(0. for i in range(len(classes)))\n\n  model.eval()\n\n  for data, target in tqdm(test_loader):\n      if torch.cuda.is_available(): \n          data, target = data.cuda(), target.cuda()\n      with torch.no_grad():\n        output = model(data)\n        loss = criterion(output, target)\n      test_loss += loss.item()*data.size(0)\n      _, pred = torch.max(output, 1)    \n      correct_tensor = pred.eq(target.data.view_as(pred))\n      correct = np.squeeze(correct_tensor.numpy()) if not torch.cuda.is_available() else np.squeeze(correct_tensor.cpu().numpy())\n      if len(target) == 64:\n        for i in range(64):\n            label = target.data[i]\n            class_correct[label] += correct[i].item()\n            class_total[label] += 1\n\n  test_loss = test_loss/len(test_loader.dataset)\n  print('Test Loss: {:.6f}\\n'.format(test_loss))\n\n  for i in range(len(classes)):\n      if class_total[i] > 0:\n          print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n              classes[i], 100 * class_correct[i] / class_total[i],\n              np.sum(class_correct[i]), np.sum(class_total[i])))\n      else:\n          print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n\n  print('\\nTest Accuracy (Overall): {:.4f} ({}/{})'.format(\n      100. * np.sum(class_correct) / np.sum(class_total),\n      np.sum(class_correct), np.sum(class_total)))\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2022-06-25T13:59:21.600913Z\",\"iopub.execute_input\":\"2022-06-25T13:59:21.601517Z\",\"iopub.status.idle\":\"2022-06-25T14:03:17.487406Z\",\"shell.execute_reply.started\":\"2022-06-25T13:59:21.601485Z\",\"shell.execute_reply\":\"2022-06-25T14:03:17.486427Z\"}}\ntest(model_ft)\n\n# %% [code]\nexample = torch.rand(1, 3, 224, 224)\ntraced_script_module = torch.jit.trace(model_ft.cpu(), example)\ntraced_script_module.save(\"birds-325-efficientnetb1.zip\")\n\n# %% [code]\n\n\n# %% [code]\n\n\n# %% [code]\n\n\n# %% [code]\n\n\n# %% [code]\n\n\n# %% [code]\n\n\n# %% [code]\n\n\n# %% [code]\n\n\n# %% [code]\n\n\n# %% [code]\n\n\n# %% [code]\n\n\n# %% [code]\n\n\n# %% [code]\n\n\n# %% [code]\n\n\n# %% [code]\n\n\n# %% [code]\n\n\n# %% [code]\n\n\n# %% [code]\n\n\n# %% [code]\n\n\n# %% [code]\n","metadata":{"_uuid":"a12bb00b-ef52-4f48-8eff-3aad9e3a4769","_cell_guid":"20f31c07-d9ff-4e18-8f50-ad8ca8a7f0ea","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}
